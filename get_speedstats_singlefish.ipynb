{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate burst-glide statistics and lower-frequency speed changes for each fish in a trial\n",
    "\n",
    "### Using speed data for each fish:\n",
    "   - identify time windows without tracking errors/gaps\n",
    "   - identify burst timing and features (max speed, peak-valley amplitude, rise time, fall time, potentially fit parameters)\n",
    "   - get sliding burst rate and smoothed speed over time for analyzing speed crosscorrelation in lower frequencies\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import needed modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd  \n",
    "import glob\n",
    "import get_kinematics_adult as kin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define directories and import list of lines\n",
    "datadir = '../data/'\n",
    "resultdir = 'savedresults/'\n",
    "\n",
    "[treatments] = pickle.load(open(resultdir+'treatmentlist.pkl','rb'))\n",
    "treatments = np.array(treatments)\n",
    "numtreatments = len(treatments)\n",
    "[focustreatments,notfocus] = pickle.load(open(resultdir+'focustreatmentlist.pkl','rb'))\n",
    "[allnumtrials] = pickle.load(open(resultdir+'allnumtrials.pkl','rb'))\n",
    "\n",
    "pxpercm = 4.02361434 * 10  # from tracker\n",
    "dt=1/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import single line\n",
    "tnum = 0  # select which line, 0 = WT\n",
    "treatment = treatments[tnum]\n",
    "numtrials = allnumtrials[tnum]\n",
    "[trial_speeds,trial_trajectories,trial_headings,trial_theta,\n",
    "            trial_smoothspeeds,trial_smoothtrajectories,trial_smoothheadings,\n",
    "            trial_ellipses,trial_arena,trial_sex,\n",
    "            datafiles,trial_trackingerrors] = pickle.load(open(datadir+treatment+'-alltrials.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load fishpair distances from file\n",
    "filename = datadir+treatment+'-dcoords+dist-heading.pkl'\n",
    "[trial_dcoords,trial_dist] = pickle.load(open(filename,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trial_headings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select single trial for line and fish to include in analysis \n",
    "#(later: setup to iterate through all trials & save relevant data)\n",
    "trialnum = 0\n",
    "fishIncl = np.arange(6)\n",
    "nframes = trial_trajectories[trialnum].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify frames with bad data for each fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize badData dataframe; types: nan, flatspeed, doubleID (note which), other\n",
    "errType = pd.DataFrame(np.zeros([nframes,fishIncl.size], dtype=int), columns = ['fish0','fish1','fish2','fish3','fish4','fish5'])\n",
    "errType.index.name = 'frame'\n",
    "errType.head()\n",
    "errCode = {0: 'noError',\n",
    " 1: 'missing',\n",
    " 2: 'flatSpeed',\n",
    " 30: 'doubleID_0',\n",
    " 31: 'doubleID_1',\n",
    " 32: 'doubleID_2',\n",
    " 33: 'doubleID_3',\n",
    " 34: 'doubleID_4',\n",
    " 35: 'doubleID_5'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add nans/missing data to errType\n",
    "errs = trial_trackingerrors[trialnum][:,fishIncl].copy()\n",
    "errType[errs] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find flatspeed for each fish - speed does not change (or change < threshold) for >t duration; define as baddata\n",
    "speeds = trial_speeds[trialnum].copy()\n",
    "accel = np.gradient(speeds,axis=0)\n",
    "accel[1:] = speeds[1:]-speeds[0:-1]\n",
    "accel[np.isnan(accel)] = 1.0 #set nans to real value > threshold\n",
    "errs = (np.abs(accel)<0.001)\n",
    "errType[errs] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kin.getBGcycle(speeds[:,0]) #need to do something about nans or mod kin to deal with them before this will work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define baddata for at least one fish in pair when [dist,oridiff] < threshold (doubleID error)\n",
    "\n",
    "#for each fishpair, each time point, get distance (trial_dist from file) and orientation diff (subtr heading)\n",
    "dthresh = pxpercm #1 cm, ~40 pixels; same threshold used in paper; I may use looser threshold\n",
    "othresh = .2 #taken from paper\n",
    "\n",
    "for i in fishIncl:\n",
    "    col0 = errType.columns[i]\n",
    "    errcode1 = 30 + i\n",
    "    for j in range(i+1,fishIncl.size):\n",
    "        col1 = errType.columns[j]\n",
    "        errcode0 = 30 +j\n",
    "        dpair = trial_dist[trialnum][:,i,j].copy() \n",
    "        dpair[np.isnan(dpair)] = 100 #set nans to high values to avoid invalid values and false errID\n",
    "        oridiff = trial_headings[trialnum][:,i]-trial_headings[trialnum][:,j]\n",
    "        oridiff[np.isnan(oridiff)] = 6 #set nans to high values to avoid invalid values and false errID\n",
    "        indErr = (abs(oridiff) < othresh) & (dpair < dthresh)\n",
    "        errType.loc[indErr,col0] = errcode0\n",
    "        errType.loc[indErr,col1] = errcode1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WT\\\\data09092015_10_26_AMAB.mat'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restore speed and position for nans during bursts (were filtered by accel filter in orig data processing)\n",
    "timeTH = 25 #preliminary guess for threshold\n",
    "speedTH = 500 #preliminary guess for threshold\n",
    "errcode = 8\n",
    "\n",
    "groupdatadir = datadir + '/raw/' + treatment +'/'\n",
    "datafiles = np.sort([str.split(s,'/')[-1] for s in glob.glob(groupdatadir+'*mat')])\n",
    "\n",
    "#open datafile (one for now, set to iterate through after tests); get trajectories, speed, heading\n",
    "data = loadmat(datafiles[trialnum])\n",
    "def loadval(dictval):\n",
    "    return np.array([t[0][0] for t in (np.array(data['trx'][dictval]).T)]) \n",
    "data_x = loadval('x')\n",
    "data_y = loadval('y')\n",
    "trajectories_raw = np.array([data_x,data_y]).T\n",
    "velocities = np.gradient(trajectories,axis=0)/dt #if these are too slow, could do just for regions of interest\n",
    "speeds = np.sqrt(velocities[:,:,0]**2 + velocities[:,:,1]**2) \n",
    "headings = np.arctan2(velocities[:,:,1],velocities[:,:,0]) \n",
    "\n",
    "#for fish in fishIncl:\n",
    "    #find regions of interest: criteria: NaN value, duration < fthresh, speedmax - speedmin > speedTH\n",
    "        #to do, make array: for each errType == 1, col1 : last errType == 0, col2: next errType == 0; \n",
    "        #err1bouts = unique rows in array\n",
    "        #for each err1bout, get: speedchange (after-before), bouttime; \n",
    "        #if speedchange > speedTH & bouttime < timeTH, add bout to regions\n",
    "    #for region in regions:\n",
    "        #assign new errortype for region\n",
    "        #replace trajectories w raw \n",
    "        #replace speed \n",
    "        #compute ori for region\n",
    "        #maybe compute other params (draw from \"data import and smoothing\" code)\n",
    "\n",
    "#??resave pickle? or new pickle? undecided, could also keep local if not too slow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots to validate errtypes, burstgap fixes, overall data quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe look for small sharp oscillations? hard to define though, skip for now and maybe come back later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe: kernel or wavelet smooth; don't want to do for now (I think burst coordination analysis may be better w/o it) but consider for later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find bursts in speed trajectory\n",
    "\n",
    "   - Build on get_kinematics function for getting BGCycle\n",
    "   - Tweak parameters for burst detection (especially nback)\n",
    "   - Maybe: try w both smoothed and raw trajectories, see which is better\n",
    "   - Either only do for good trajectories, or note when burst is baddata"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
