{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate burst-glide statistics and lower-frequency speed changes for each fish in a trial\n",
    "\n",
    "### Using speed data for each fish:\n",
    "   - identify time windows without tracking errors/gaps\n",
    "   - identify burst timing and features (max speed, peak-valley amplitude, rise time, fall time, potentially fit parameters)\n",
    "   - get sliding burst rate and smoothed speed over time for analyzing speed crosscorrelation in lower frequencies\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import needed modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd  # just using this to display things nicely\n",
    "import get_kinematics_adult as kin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define directories and import list of lines\n",
    "datadir = '../data/'\n",
    "resultdir = 'savedresults/'\n",
    "\n",
    "[treatments] = pickle.load(open(resultdir+'treatmentlist.pkl','rb'))\n",
    "treatments = np.array(treatments)\n",
    "numtreatments = len(treatments)\n",
    "[focustreatments,notfocus] = pickle.load(open(resultdir+'focustreatmentlist.pkl','rb'))\n",
    "[allnumtrials] = pickle.load(open(resultdir+'allnumtrials.pkl','rb'))\n",
    "\n",
    "pxpercm = 4.02361434 * 10  # from tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import single line\n",
    "tnum = 0  # select which line, 0 = WT\n",
    "treatment = treatments[tnum]\n",
    "numtrials = allnumtrials[tnum]\n",
    "[trial_speeds,trial_trajectories,trial_headings,trial_theta,\n",
    "            trial_smoothspeeds,trial_smoothtrajectories,trial_smoothheadings,\n",
    "            trial_ellipses,trial_arena,trial_sex,\n",
    "            datafiles,trial_trackingerrors] = pickle.load(open(datadir+treatment+'-alltrials.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load fishpair distances from file\n",
    "filename = datadir+treatment+'-dcoords+dist-heading.pkl'\n",
    "[trial_dcoords,trial_dist] = pickle.load(open(filename,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.16317914, -1.9180828 , -1.79156783, -1.06572235, -1.82983046,\n",
       "        -1.34165018],\n",
       "       [-1.16939637, -1.88617661, -1.79994801, -1.10705365, -1.83903158,\n",
       "        -1.3358294 ],\n",
       "       [-1.16814989, -1.807371  , -1.66897862, -1.18188492, -1.8484831 ,\n",
       "        -1.32891067],\n",
       "       ...,\n",
       "       [-0.11442442,         nan,  2.41916635,         nan,  2.44419482,\n",
       "        -0.64016974],\n",
       "       [-0.12035425,         nan,  2.35126817,         nan,  2.45406425,\n",
       "        -0.60138212],\n",
       "       [-0.097265  ,         nan,  2.32842505,         nan,  2.49272354,\n",
       "        -0.57112364]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_headings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select single trial for line and fish to include in analysis \n",
    "#(later: setup to iterate through all trials & save relevant data)\n",
    "trialnum = 0\n",
    "fishIncl = np.arange(6)\n",
    "nframes = trial_trajectories[trialnum].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify frames with bad data for each fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize badData dataframe; types: nan, flatspeed, doubleID (note which), other\n",
    "errType = pd.DataFrame(np.zeros([nframes,fishIncl.size], dtype=int), columns = ['fish0','fish1','fish2','fish3','fish4','fish5'])\n",
    "errType.index.name = 'frame'\n",
    "errType.head()\n",
    "errCode = {0: 'noError',\n",
    " 1: 'missing',\n",
    " 2: 'flatSpeed',\n",
    " 30: 'doubleID_0',\n",
    " 31: 'doubleID_1',\n",
    " 32: 'doubleID_2',\n",
    " 33: 'doubleID_3',\n",
    " 34: 'doubleID_4',\n",
    " 35: 'doubleID_5'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add nans/missing data to errType\n",
    "errs = trial_trackingerrors[trialnum][:,fishIncl].copy()\n",
    "errType[errs] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find flatspeed for each fish - speed does not change (or change < threshold) for >t duration; define as baddata\n",
    "speeds = trial_speeds[trialnum].copy()\n",
    "accel = np.gradient(speeds,axis=0)\n",
    "accel[1:] = speeds[1:]-speeds[0:-1]\n",
    "accel[np.isnan(accel)] = 1.0 #set nans to real value > threshold\n",
    "errs = (np.abs(accel)<0.001)\n",
    "errType[errs] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define baddata for at least one fish in pair when [dist,oridiff] < threshold (doubleID error)\n",
    "\n",
    "#for each fishpair, each time point, get distance (trial_dist from file) and orientation diff (subtr heading)\n",
    "dthresh = pxpercm #1 cm, ~40 pixels; same threshold used in paper; I may use looser threshold\n",
    "othresh = .2 #taken from paper\n",
    "\n",
    "for i in fishIncl:\n",
    "    col0 = errType.columns[i]\n",
    "    errcode1 = 30 + i\n",
    "    for j in range(i+1,fishIncl.size):\n",
    "        col1 = errType.columns[j]\n",
    "        errcode0 = 30 +j\n",
    "        dpair = trial_dist[trialnum][:,i,j].copy() \n",
    "        dpair[np.isnan(dpair)] = 100 #set nans to high values to avoid invalid values and false errID\n",
    "        oridiff = trial_headings[trialnum][:,i]-trial_headings[trialnum][:,j]\n",
    "        oridiff[np.isnan(oridiff)] = 6 #set nans to high values to avoid invalid values and false errID\n",
    "        indErr = (abs(oridiff) < othresh) & (dpair < dthresh)\n",
    "        errType.loc[indErr,col0] = errcode0\n",
    "        errType.loc[indErr,col1] = errcode1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore speed and position for nans during bursts (were filtered by accel filter in orig data processing)\n",
    "\n",
    "#criteria: NaN value, duration < tthresh, speedmax - speedmin > bthresh, speedpost(ave over nbins) > maxspthresh\n",
    "#assign new errortype\n",
    "#open relevant trajectory folder & file\n",
    "# get speed, pos, & ori from raw trajectories, \n",
    "# ?? resave pickle? prb no, but uncert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots to validate errtypes, burstgap fixes, overall data quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe look for small sharp oscillations? hard to define though, skip for now and maybe come back later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe: kernel or wavelet smooth; don't want to do for now (I think burst coordination analysis may be better w/o it) but consider for later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find bursts in speed trajectory\n",
    "\n",
    "   - Build on get_kinematics function for getting BGCycle\n",
    "   - Tweak parameters for burst detection (especially nback)\n",
    "   - Maybe: try w both smoothed and raw trajectories, see which is better\n",
    "   - Either only do for good trajectories, or note when burst is baddata"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
