{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate burst-glide statistics and lower-frequency speed changes for each fish in a trial\n",
    "\n",
    "### Using speed data for each fish:\n",
    "   - identify time windows without tracking errors/gaps\n",
    "   - identify burst timing and features (max speed, peak-valley amplitude, rise time, fall time, potentially fit parameters)\n",
    "   - get sliding burst rate and smoothed speed over time for analyzing speed crosscorrelation in lower frequencies\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import needed modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd  \n",
    "from scipy.io import loadmat\n",
    "import glob\n",
    "import get_kinematics_adult as kin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define directories and import list of lines\n",
    "datadir = '../data/'\n",
    "resultdir = 'savedresults/'\n",
    "\n",
    "[treatments] = pickle.load(open(resultdir+'treatmentlist.pkl','rb'))\n",
    "treatments = np.array(treatments)\n",
    "numtreatments = len(treatments)\n",
    "[focustreatments,notfocus] = pickle.load(open(resultdir+'focustreatmentlist.pkl','rb'))\n",
    "[allnumtrials] = pickle.load(open(resultdir+'allnumtrials.pkl','rb'))\n",
    "\n",
    "pxpercm = 4.02361434 * 10  # from tracker\n",
    "dt=1/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import single line\n",
    "tnum = 0  # select which line, 0 = WT\n",
    "treatment = treatments[tnum]\n",
    "numtrials = allnumtrials[tnum]\n",
    "[trial_speeds,trial_trajectories,trial_headings,trial_theta,\n",
    "            trial_smoothspeeds,trial_smoothtrajectories,trial_smoothheadings,\n",
    "            trial_ellipses,trial_arena,trial_sex,\n",
    "            datafiles,trial_trackingerrors] = pickle.load(open(datadir+treatment+'-alltrials.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load fishpair distances from file\n",
    "filename = datadir+treatment+'-dcoords+dist-heading.pkl'\n",
    "[trial_dcoords,trial_dist] = pickle.load(open(filename,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select single trial for line and fish to include in analysis \n",
    "#define speed, position, & orientatino for current trial \n",
    "#(to do: set up to iterate through all trials & save relevant data)\n",
    "trialnum = 8\n",
    "fishIncl = np.arange(6) #maybe unecessary\n",
    "nframes = trial_trajectories[trialnum].shape[0]\n",
    "speeds = trial_speeds[trialnum].copy()\n",
    "positions = trial_trajectories[trialnum].copy()\n",
    "ori = trial_headings[trialnum].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify frames with bad data for each fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize badData dataframe; types: nan, flatspeed, doubleID (note which), other\n",
    "errType = pd.DataFrame(np.zeros([nframes,fishIncl.size], dtype=int), columns = ['fish0','fish1','fish2','fish3','fish4','fish5'])\n",
    "errType.index.name = 'frame'\n",
    "errType.head()\n",
    "errCode = {0: 'noError',\n",
    " 1: 'missing',\n",
    " 2: 'flatSpeed',\n",
    " 30: 'doubleID_0',\n",
    " 31: 'doubleID_1',\n",
    " 32: 'doubleID_2',\n",
    " 33: 'doubleID_3',\n",
    " 34: 'doubleID_4',\n",
    " 35: 'doubleID_5'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add nans/missing data to errType\n",
    "errs = trial_trackingerrors[trialnum][:,fishIncl].copy()\n",
    "errType[errs] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find flatspeed for each fish - speed does not change (or change < threshold); define as baddata\n",
    "#currently doing for single frames, consider adding time threshold\n",
    "\n",
    "accel = np.gradient(speeds,axis=0)\n",
    "accel[1:] = speeds[1:]-speeds[0:-1]\n",
    "accel[np.isnan(accel)] = 1.0 #set nans to real value > threshold\n",
    "errs = (np.abs(accel)<0.001)\n",
    "errType[errs] = 2\n",
    "\n",
    "#to do: add time thresold for this, I think it's catching things it doesn't need to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add additional nans (not included in trackingerrors, not sure why)\n",
    "errs = np.isnan(speeds)\n",
    "errType[errs] = 1 #may change to another code, but for now treating all gaps the same way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define baddata for at least one fish in pair when [dist,oridiff] < threshold (doubleID error)\n",
    "\n",
    "#for each fishpair, each time point, get distance (trial_dist from file) and orientation diff (subtr heading)\n",
    "dthresh = pxpercm #1 cm, ~40 pixels; same threshold used in paper; I may use looser threshold\n",
    "othresh = .2 #taken from paper\n",
    "\n",
    "for i in fishIncl:\n",
    "    col0 = errType.columns[i]\n",
    "    errcode1 = 30 + i\n",
    "    for j in range(i+1,fishIncl.size):\n",
    "        col1 = errType.columns[j]\n",
    "        errcode0 = 30 +j\n",
    "        dpair = trial_dist[trialnum][:,i,j].copy() \n",
    "        dpair[np.isnan(dpair)] = 100 #set nans to high values to avoid invalid values and false errID\n",
    "        oridiff = trial_headings[trialnum][:,i]-trial_headings[trialnum][:,j]\n",
    "        oridiff[np.isnan(oridiff)] = 6 #set nans to high values to avoid invalid values and false errID\n",
    "        indErr = (abs(oridiff) < othresh) & (dpair < dthresh)\n",
    "        errType.loc[indErr,col0] = errcode0\n",
    "        errType.loc[indErr,col1] = errcode1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restore speed and position for nans during bursts \n",
    "- These were filtered by acceleration filter in original data processing, which was needed to remove tracking \"jumps\"\n",
    "- Filtering by gap duration and the speed change makes it possible to determine which of these are likely bursts and add the data back\n",
    "- Note: I'm only doing this locally for now, not resaving the pickle; may consider running through for everything and then saving if (1) it takes a long time and (2) I'm comfortable that I've validated the process well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupdatadir = datadir + 'raw/' \n",
    "datafiles = np.sort([str.split(s,'/')[-1] for s in glob.glob(groupdatadir+ treatment +'/*mat')])\n",
    "\n",
    "#open datafile (one for now, set to iterate through after tests); get trajectories, speed, heading\n",
    "data = loadmat(groupdatadir + datafiles[trialnum])\n",
    "def loadval(dictval):\n",
    "    return np.array([t[0][0] for t in (np.array(data['trx'][dictval]).T)]) \n",
    "data_x = loadval('x')\n",
    "data_y = loadval('y')\n",
    "trajectories_raw = np.array([data_x,data_y]).T\n",
    "velocities = np.gradient(trajectories_raw,axis=0)/dt #if these are too slow, could do just for regions of interest\n",
    "speeds_raw = np.sqrt(velocities[:,:,0]**2 + velocities[:,:,1]**2) \n",
    "headings_raw = np.arctan2(velocities[:,:,1],velocities[:,:,0]) \n",
    "\n",
    "#define thresholds for potential burst-gaps (time < some duration, speed change > some amount)\n",
    "errchanges = errType.diff()\n",
    "timeTH = 25 #preliminary guess for threshold\n",
    "speedTH = 500 #preliminary guess for threshold - seems to catch most, and spot checks on smaller burst-gaps look like they have clear errors in the raw speeds (e.g. step changes)\n",
    "errcode = 8\n",
    "\n",
    "for fish in fishIncl:   \n",
    "    #find regions of interest: criteria: NaN value, duration < fthresh, speedmax - speedmin > speedTH\n",
    "    aux = (errType.iloc[:,[fish]] == 1) & (errchanges.iloc[:,[fish]] == 1)\n",
    "    indstart = np.flatnonzero(aux.values)-1\n",
    "    aux = (errType.iloc[:,[fish]] == 0) & (errchanges.iloc[:,[fish]] == -1)\n",
    "    indend = np.flatnonzero(aux.values)\n",
    "    #remove cases where indstart and indend do not line up\n",
    "    aux = np.ones(indstart.size, dtype = bool)\n",
    "    for i in range(indstart.size-1):\n",
    "        if ~np.any((indend > indstart[i]) & (indend <= indstart[i+1])):\n",
    "            aux[i] = False\n",
    "    indstart = indstart[aux]\n",
    "    indstart.size\n",
    "    aux = np.ones(indend.size, dtype = bool)\n",
    "    for i in range(1,indend.size):\n",
    "        if ~np.any((indstart < indend[i]) & (indstart >= indend[i-1])):\n",
    "            aux[i] = 0\n",
    "    indend = indend[aux]\n",
    "    if indstart[-1] > indend[-1]:\n",
    "        indstart = indstart[:-1]\n",
    "    if indstart[0] > indend[0]:\n",
    "        indend = indend[1:]\n",
    "    \n",
    "    #filter for possible bursts\n",
    "    gapdata = np.vstack([indend-indstart,speeds[indend,fish]-speeds[indstart,fish]]).T\n",
    "    burstgap = np.where((gapdata[:,0] < timeTH) & (gapdata[:,1] > speedTH))[0] #possible excluded bursts\n",
    "    \n",
    "    #replace speed, trajectory, and heading with raw data for putative excluded bursts\n",
    "    for gap in burstgap:\n",
    "        errType.iloc[indstart[gap]:indend[gap],[fish]] = errcode #assign new errortype for timewindow, to keep track of (may remove later)\n",
    "        positions[indstart[gap]:indend[gap],fish] = trajectories_raw[indstart[gap]:indend[gap],fish]  \n",
    "        ori[indstart[gap]:indend[gap],fish] = headings_raw[indstart[gap]:indend[gap],fish]\n",
    "        speeds[indstart[gap]:indend[gap],fish] = speeds_raw[indstart[gap]:indend[gap],fish] \n",
    "\n",
    "#??resave pickle? or new pickle? not doing currently, but may add later if this is too slow to repeat each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plots to validate errtypes, burstgap fixes, overall data quality\n",
    "fish = 0\n",
    "minframe= 11200\n",
    "duration = 800\n",
    "maxframe = minframe + duration\n",
    "xx = positions[minframe:maxframe,fish,0]\n",
    "yy = positions[minframe:maxframe,fish,1]\n",
    "# for orientations, best to use 'smoothheadings'\n",
    "orientations = ori[minframe:maxframe,fish]\n",
    "spd = speeds[minframe:maxframe,fish]\n",
    "errs = errType.iloc[minframe:maxframe,[fish]]\n",
    "\n",
    "# plot orientation and speed, and (opt) nan values\n",
    "f,ax=plt.subplots(3,1,sharex=True)\n",
    "f.set_size_inches(14,10)\n",
    "a = ax[0]\n",
    "a.plot(np.arange(minframe,maxframe),spd)\n",
    "a.set_ylim([0,1800])\n",
    "a.set_title('Speed')\n",
    "a = ax[1]\n",
    "a.plot(np.arange(minframe,maxframe),orientations)\n",
    "a.set_title('Orientation')\n",
    "a = ax[2]\n",
    "a.plot(np.arange(minframe,maxframe),errs)\n",
    "a.set_title('ErrorType')\n",
    "\n",
    "# a = ax[6]\n",
    "# a.plot(np.isnan(speeds))\n",
    "# a.set_title('NaN values')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find bursts in speed trajectory\n",
    "\n",
    "   - Build on get_kinematics function for getting BGCycle\n",
    "   - Tweak parameters for burst detection (especially nback)\n",
    "   - Maybe: try w both smoothed and raw trajectories, see which is better\n",
    "   - Either only do for good trajectories, or note when burst is baddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.arange(nframes)*dt\n",
    "burstmat, burstrate = kin.getBGcycle(speeds[:,0], time = time, nbins = 4, threshold = 250.0, burstHtthresh = 100.0) \n",
    "burstmat.set_index('n',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#oriAligned = kin.getTurns(ori[fish],bursts,time) #needs to be adapted\n",
    "#timeInactive = kin.getSwimTime(speed,time) #need to adapt for nans, maybe other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plots to check burst detection\n",
    "\n",
    "# for testing/debug\n",
    "f0, axs = plt.subplots(6,1, figsize=(16,24))\n",
    "\n",
    "nplots = 6\n",
    "twinstarts = np.arange(0,800*nplots,800) \n",
    "twinsize = 800 #\n",
    "\n",
    "for i in range(nplots):\n",
    "    twinstart = twinstarts[i]\n",
    "    twinend = twinstart+twinsize\n",
    "    ind = np.arange(twinstart,twinsize+twinstart)\n",
    "    axs[i].plot(time[ind], speeds[ind,0])\n",
    "    axs[i].set_title('Fish0 Speed')\n",
    "    axs[i].set_ylim([0,2200])\n",
    "\n",
    "    bstart = burstmat.loc[(burstmat['valleyTime'] > time[twinstart]) & (burstmat['valleyTime'] < time[twinend]),['valleyTime']].values\n",
    "    bpeak = burstmat.loc[(burstmat['valleyTime'] > time[twinstart]) & (burstmat['valleyTime'] < time[twinend]),['peakTime']].values\n",
    "    bb = np.hstack([bstart,bpeak])\n",
    "\n",
    "    #plot speed vs time or counter\n",
    "    for xc in bb:\n",
    "        axs[i].axvline(x = xc[0],color='deepskyblue')\n",
    "        axs[i].axvline(x = xc[1],color='mediumseagreen')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe: kernel or wavelet smooth; don't want to do for now (I think burst coordination analysis may be better w/o it) but consider for later"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
